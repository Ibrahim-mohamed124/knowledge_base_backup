<!--
title: Backup, Restore, and Migration.
description: 
published: true
date: 2025-11-11T10:36:49.369Z
tags: 
editor: ckeditor
dateCreated: 2025-11-07T08:07:57.224Z
-->

<h1>Chapter&nbsp;2.&nbsp; Backup, Restore, and Migration of Applications with OADP</h1>
<ul>
  <li>To restore an application fully in k8s the following objects must be backed up:<ul>
      <li>Kubernetes <mark class="marker-yellow">resources</mark> that define the application and its settings.</li>
      <li><mark class="marker-yellow">Container images </mark>in the internal registry that containers of this application use.</li>
      <li><mark class="marker-yellow">Data</mark> that is stored in persistent volumes or object storage for a stateful application.</li>
    </ul>
  </li>
</ul>
<h3>Backing Up Application Resources</h3>
<ul>
  <li>Backing up an entire application involves:<ul>
      <li>Listing all the application resources</li>
      <li>Exporting the application resources</li>
      <li>Cleaning the application resources</li>
      <li>Deploying the cleaned resources</li>
    </ul>
  </li>
</ul>
<blockquote>
  <p>yq utility is very useful to clean unwanted attributes from a yaml file</p>
</blockquote>
<h3>Backing Up Container Images</h3>
<ul>
  <li>Podman and Skopeo</li>
  <li>To access the registry from outside the cluster or to export images from your local machine, an OpenShift administrator must expose the registry externally.</li>
</ul>
<pre><code class="language-plaintext">oc patch \
  configs.imageregistry.operator.openshift.io/cluster \
  --patch '{"spec":{"defaultRoute":true}}' \
  --type merge</code></pre>
<p>&nbsp;</p>
<blockquote>
  <p>The modification to the image registry operator triggers a redeployment of the OpenShift API server. It can take up to 10 minutes for the cluster to stabilize.</p>
</blockquote>
<ul>
  <li>The operator creates a <code>default-route</code> route to expose externally the registry that uses the following URL format:</li>
</ul>
<pre><code class="language-plaintext">default-route-openshift-image-registry.apps-domain</code></pre>
<p>&nbsp;</p>
<pre><code class="language-plaintext"> REGISTRY=$(oc get \
  route default-route \
  -n openshift-image-registry \
  --template '{{.spec.host}}')</code></pre>
<p>&nbsp;</p>
<ul>
  <li>OpenShift users who do not have access to the <code>openshift-image-registry</code> namespace can retrieve the registry URL from any image stream:</li>
</ul>
<pre><code class="language-plaintext">oc -n openshift get is/cli \
  -ojsonpath="{.status.publicDockerImageRepository}{'\n'}"
</code></pre>
<ul>
  <li>You can then log in to the internal registry by using your OpenShift username and authentication token with the following command:</li>
</ul>
<pre><code class="language-plaintext">podman login \
  -u $(oc whoami) \
  -p $(oc whoami -t) \
  --tls-verify=false \
  $REGISTRY</code></pre>
<p>&nbsp;</p>
<ul>
  <li>The <code>oc registry login</code> command automatically uses your authentication token and the internal registry URL from the OpenShift cluster.</li>
  <li>The <code>oc</code> command stores the credentials in the <code>${HOME}/.docker/config.json</code> file in Base64 format. The Podman, Skopeo, and Docker clients can use the authentication details from that file to access an image registry.</li>
</ul>
<pre><code class="language-plaintext">oc registry login</code></pre>
<h4>Export Container Images</h4>
<pre><code class="language-plaintext">skopeo copy \
  docker://${REGISTRY}/project_name/imagestream:tag \ 1
  docker://remote-registry.example.com/path/to/image:remotetag 2
  
1. Fully qualified source image in the OpenShift internal registry &gt;&gt; exposed externally to export
images from outside the cluster

2. Destination registry URL with image and tag information</code></pre>
<p>&nbsp;</p>
<blockquote>
  <p>Skopeo can copy images to other locations such as a local directory or a <code>.tar</code> archive.</p>
</blockquote>
<p>or</p>
<pre><code class="language-plaintext">podman pull ${REGISTRY}/project_name/imagestream:tag

podman save ${REGISTRY}/project_name/imagestream:tag \
  | bzip2 &gt; image_backup.tar.bz2</code></pre>
<p>or</p>
<pre><code class="language-plaintext">oc image mirror ${REGISTRY}/project_name/imagestream:* \ 1
  remote-registry.example.com/path/to/image
  
1. You can use the wildcard character (*) to copy all the tags to the destination registry.

</code></pre>
<p>&nbsp;</p>
<ul>
  <li>To export a container image from within the cluster, you can use any available container tools in a pod to copy the image to the location of your choice, such as a persistent volume on NFS storage, S3 storage, or a remote registry.</li>
</ul>
<pre><code class="language-plaintext">apiVersion: batch/v1
kind: Job
metadata:
  name: backup-image
  namespace: application
  labels:
    app: backup
spec:
  backoffLimit: 1
  template:
    metadata:
      labels:
        app: backup
    spec:
      containers:
      - name: backup
        image: image-registry.openshift-image-registry.svc:5000/openshift/cli:latest
        env:
        - name: REGISTRY_AUTH_FILE
          value: /tmp/dockercfg.json
        command: ["/bin/bash", "-c"]
        args:
        - | 1
          oc registry login
          oc image mirror \
            image-registry.openshift-image-registry.svc:5000/application/myapp:* \
            file://myapp --dir /backup
        volumeMounts: 2
          - mountPath: /backup
            name: backup
      ...output omitted...
      volumes: 3
      - name: backup
        persistentVolumeClaim:
          claimName: backup-volume
          
1. Log in to the internal registry and export all tags of the myapp image stream to the /backup path.

2. Volume mount definition for the backup location.

3. Volume definition for the backup persistent volume claims (PVC).</code></pre>
<p>&nbsp;</p>
<ul>
  <li>You need the <code>system:image-puller</code> role on the OpenShift project to pull images from any image streams in that project. Project users and administrators already have this permission, as well as the <code>default</code> service account.</li>
</ul>
<h4>Import Container Images</h4>
<pre><code class="language-plaintext">skopeo copy \
  docker://remote-registry.example.com/myimage:latest \
  docker://${REGISTRY}/project_name/mynewimagestream:latest</code></pre>
<p>&nbsp;</p>
<p>or</p>
<pre><code class="language-plaintext"> oc image mirror \
  remote-registry.example.com/myimage:latest \
  ${REGISTRY}/project_name/mynewimagestream:latest</code></pre>
<p>&nbsp;</p>
<p>or</p>
<pre><code class="language-plaintext">podman load -i image_backup.tar.bz2

podman tag \
  registry.apps.ocp4.example.com/application/myapp:1.2.3 \
  ${REGISTRY}/newproject/myapp:1.2.3
  
podman push ${REGISTRY}/newproject/myapp:1.2.3</code></pre>
<p>&nbsp;</p>
<blockquote>
  <p>You need the <code>system:image-pusher</code> role on the OpenShift project to push images to any image streams in that project. Project users and administrators already have this permission, as well as the <code>builder</code> service account.</p>
</blockquote>
<h3>Backing Up Application Data</h3>
<ul>
  <li>Different consistency levels can be achieved depending on the backup method.<ul>
      <li><strong>Inconsistent backup</strong>
        <ul>
          <li>A backup is called inconsistent when the<mark class="marker-yellow"> application alters data during the backup process</mark>. Traditional data copying when the application is running creates inconsistent backups.</li>
        </ul>
      </li>
      <li><strong>Crash-consistent backup</strong>
        <ul>
          <li>A crash-consistent backup is created by suspending disk I/O during the backup, either by using snapshot technology or specialized tools, to ensure data consistency on disk. <mark class="marker-yellow">Application data in memory or pending I/O operations are not captured.</mark> The state of the application is kept as if the application was suddenly shut down due to power loss, or crashed.</li>
        </ul>
      </li>
      <li><strong>Application-consistent backup</strong>
        <ul>
          <li>Application-consistent backup is the most reliable type of backup because it <mark class="marker-yellow">ensures that all in-memory data and pending I/O operations are written on disk before creating the backup</mark>.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Some applications provide a set of tools to flush memory data to disk and to pause file system operations on demand. These tools provide an application-consistent backup without any downtime by using snapshots, and is also known as<mark class="marker-yellow"> </mark><i><mark class="marker-yellow">hot backup</mark></i><mark class="marker-yellow">.</mark></li>
  <li>A more universal way to create application-consistent backup is to stop the application, copy the data to another location, and then restart the application. This method is also called<mark class="marker-yellow"> </mark><i><mark class="marker-yellow">cold backup</mark></i><mark class="marker-yellow">,</mark> because the application is down during the operation.</li>
  <li>These pervious methods can halt the application for long time, so a better approach is to use volume snapshots. CSI takes a snapshot of certain volume and the backup can be created from the cloned volume without any effect on the application performance.</li>
</ul>
<h4>Volume Snapshot</h4>
<ul>
  <li>Container Storage Interface (CSI) drivers that support volume snapshots:</li>
</ul>
<figure class="table">
  <table style="background-color:rgb(255, 255, 255);">
    <thead>
      <tr>
        <th style="padding:5px;vertical-align:top;"><strong>Storage provider</strong></th>
        <th style="padding:5px;vertical-align:top;"><strong>CSI driver</strong></th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td style="padding:5px;vertical-align:top;">AWS Elastic Block Storage</td>
        <td style="padding:5px;vertical-align:top;"><code>efs.csi.aws.com</code></td>
      </tr>
      <tr>
        <td style="padding:5px;vertical-align:top;">Azure Disk</td>
        <td style="padding:5px;vertical-align:top;"><code>disk.csi.azure.com</code></td>
      </tr>
      <tr>
        <td style="padding:5px;vertical-align:top;">CephFS</td>
        <td style="padding:5px;vertical-align:top;"><code>cephfs.csi.ceph.com</code></td>
      </tr>
      <tr>
        <td style="padding:5px;vertical-align:top;">Ceph RBD</td>
        <td style="padding:5px;vertical-align:top;"><code>rbd.csi.ceph.com</code></td>
      </tr>
      <tr>
        <td style="padding:5px;vertical-align:top;">NetApp</td>
        <td style="padding:5px;vertical-align:top;"><code>csi.trident.netapp.i</code></td>
      </tr>
    </tbody>
  </table>
</figure>
<ul>
  <li><strong>VolumeSnapshotClass:</strong>
    <ul>
      <li>a volume snapshot class describes the CSI driver and associated settings to create a volume snapshot.</li>
      <li>The <code>VolumeSnapshotClass</code> driver must match the <code>StorageClass</code> provisioner of the source PVC.</li>
    </ul>
  </li>
</ul>
<pre><code class="language-plaintext">oc get volumesnapshotclasses

apiVersion: snapshot.storage.k8s.io/v1
kind: VolumeSnapshotClass
metadata:
  name: csi-hostpath-snapclass
driver: hostpath.csi.k8s.io
deletionPolicy: Delete
parameters:</code></pre>
<p>&nbsp;</p>
<ul>
  <li><strong>VolumeSnapshot:</strong></li>
</ul>
<pre><code class="language-plaintext">oc get volumesnapshot

apiVersion: snapshot.storage.k8s.io/v1
kind: VolumeSnapshot
metadata:
  name: my-snapshot 1
  namespace: application 2
spec:
  volumeSnapshotClassName: ocs-storagecluster-rbdplugin-snapclass 3
  source:
    persistentVolumeClaimName: application-data 4
    
1. Name of the volume snapshot.

2. Namespace of the volume snapshot. It must be the same as the source PVC.

3. Snapshot class name for the volume snapshot.

4. Name of the source PVC that is used for the snapshot.</code></pre>
<p>&nbsp;</p>
<blockquote>
  <p>When creating an application-consistent backup, the application must be quiesced or scaled down before the snapshot creation. The application can safely be resumed or scaled up after the snapshot is created and ready to use.</p>
</blockquote>
<ul>
  <li><strong>VolumeSnapshotContent:</strong>
    <ul>
      <li>a <code>VolumeSnapshotContent</code> resource represents a snapshot that a <code>VolumeSnapshot</code> resource created.</li>
      <li>After the snapshot is created, it can function as a source to create a PVC and for a pod to use it.</li>
    </ul>
  </li>
</ul>
<pre><code class="language-plaintext">apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: my-snapshot-volume 1
  namespace: application 2
spec:
  storageClassName: ocs-external-storagecluster-ceph-rbd 3
  accessModes:
  - ReadWriteOnce
  dataSource:
    apiGroup: snapshot.storage.k8s.io
    kind: VolumeSnapshot
    name: my-snapshot 4
  resources:
    requests:
      storage: 1Gi 5
      
1. Name of the PVC.

2. Namespace of the PVC. It must be the same as the snapshot namespace.

3. Storage class name for the PVC.

4. Name of the snapshot.

5. Size of the new volume. Must be equal to or greater than the snapshot size.

</code></pre>
<h4>Export Application Data</h4>
<pre><code class="language-plaintext">apiVersion: batch/v1
kind: Job
metadata:
  name: backup
  namespace: application
  labels:
    app: backup
spec:
  backoffLimit: 1
  template:
    metadata:
      labels:
        app: backup
    spec:
      containers:
      - name: backup
        image: docker.io/d3fk/s3cmd:latest
        command: ["/bin/sh", "-c"]
        args:
        - | 1
          tar czf -C /snapshot /tmp/mybackup.tar.gz .
          s3cmd cp /tmp/mybackup.tar.gz s3://backup/
        volumeMounts: 2
          - mountPath: /snapshot
            name: snapshot
      ...output omitted...
      volumes: 3
      - name: snapshot
        persistentVolumeClaim:
          claimName: my-snapshot-volume
1. Archive the snapshot content and copy the archive to a remote S3 bucket.

2. Volume mount definition for the snapshot data in the container.

3. Volume definition for the snapshot PVC.</code></pre>
<p>&nbsp;</p>
<ul>
  <li>To export the snapshot content locally from a pod by using the <code>oc cp</code> command.</li>
</ul>
<pre><code class="language-plaintext">apiVersion: v1
kind: Pod
metadata:
  name: export
spec:
  containers:
  - image: registry.access.redhat.com/ubi9:latest
    command: ["/bin/bash", "-c"]
    args:
    - sleep infinity 1
    ...output omitted...
    volumeMounts: 2
      - mountPath: /snapshot
        name: snapshot
  volumes: 3
  - name: snapshot
    persistentVolumeClaim:
      claimName: my-snapshot-volume
1. The sleep infinity command ensures that the pod stays alive during the manual export.

2. Volume mount definition for the snapshot data in the container.

3. Volume definition for the snapshot PVC.</code></pre>
<p>&nbsp;</p>
<pre><code class="language-plaintext"> oc cp export:/snapshot /tmp/backup</code></pre>
<p>&nbsp;</p>
<blockquote>
  <p>The <code>tar</code> binary must be installed in the remote container for the <code>oc cp</code> command to work.</p>
</blockquote>
<h4>Import Application Data</h4>
<pre><code class="language-plaintext">apiVersion: batch/v1
kind: Job
metadata:
  name: restore
  namespace: application
  labels:
    app: restore
spec:
  backoffLimit: 1
  template:
    metadata:
      labels:
        app: restore
    spec:
      containers:
      - name: restore
        image: docker.io/d3fk/s3cmd:latest
        command: ["/bin/bash", "-c"]
        args: 1
        - |
          s3cmd cp s3://backup/mybackup.tar.gz /tmp/
          tar xvzf /tmp/mybackup.tar.gz -C /data
        volumeMounts: 2
          - mountPath: /data
            name: application-data
      ...output omitted...
      volumes: 3
      - name: application-data
        persistentVolumeClaim:
          claimName: application-data
1. Install the s3cmd tool, fetch the backup from the S3 bucket, and extract the archive inside the 
application data volume.
2. Volume mount definition for the application data in the container.

3. Volume definition for the application PVC.</code></pre>
<p>&nbsp;</p>
<h2>OADP Operator Deployment and Features</h2>
<ul>
  <li>a native backup solution for applications that run on OpenShift.</li>
  <li>It depends on open source components like:<ul>
      <li><strong>Velero: </strong>provides the backup API to the users and uses plug-ins to add extended capabilities to OADP.</li>
      <li><strong>Kopia: </strong>Velero and Data Mover use to back up persistent volumes.</li>
    </ul>
  </li>
</ul>
<figure class="image image_resized" style="width:100%;"><img src="/oadp-arch.svg"></figure>
<p>&nbsp;</p>
<ul>
  <li>the main components that OADP uses:<ol>
      <li>Velero: backs up the native kubernetes resources, and integrates with openshift plug-in to back up openshift resources and internal container images</li>
      <li>Kopia: work with CSI plug-in to move the actual data in snapshots to other destinations</li>
      <li>Data Mover: export snapshot content to object storage by using Kopia and the CSI plug-in.</li>
      <li>CSI plug-in: is used to take volume snapshots and provision volumes</li>
    </ol>
  </li>
  <li>Velero not only exports and imports resources; it also performs <mark class="marker-yellow">additional processing on the resources.&nbsp;</mark>
    <ul>
      <li>Determine the correct restore order for each resource.</li>
      <li>Apply any user-provided filters.</li>
      <li>Modify the destination namespace, if it is different from the backup.</li>
      <li>Remove or alter resource attributes such as auto-assigned node ports, IP addresses, or hostnames.</li>
      <li>Skip managed resources such as a replica set that deployment owns.</li>
    </ul>
  </li>
  <li>Data Volume Snapshot could be taken by a cloud provider snapshot APIs or by the kubernetes CSI itself. If a volume does not support either of the APIs could use the file-system backup solution FBS that is implemented by Kopia.<ul>
      <li>Kopia access the volume through the volume mount point in the cluster node so the application must be running but quiesced during the backup.</li>
    </ul>
  </li>
  <li>To take <mark class="marker-yellow">consistent backups, </mark>use the backup and restore <mark class="marker-yellow">pre-hooks</mark> to run commands before and after the backup to quiesce an application, such as a transactional database, to flush pending I/O operations to the storage back end and pause future application writing operations to avoid any data loss or corruption during the backup. A <mark class="marker-yellow">post-hook </mark>is used to resume the application operations.</li>
</ul>
<blockquote>
  <p>If you use volume snapshots, then the hooks are executed just before and after the snapshot creation, which significantly reduces the time that the application is in read-only mode.</p>
</blockquote>
<ul>
  <li>OADP Data Mover: Data Mover uses Kopia to upload and encrypt snapshot content to a unified backup repository on the object storage.</li>
  <li>Velero Plug-ins: extend the OADP capabilities and backup logic by using the Velero plug-in system. Support for various cloud providers, storage solutions, and additional CRDs are available with integrated plug-ins.<ul>
      <li><code><strong>openshift</strong></code>
        <ul>
          <li>Provides additional logic to back up and restore OpenShift resources, including container images from the internal registry.</li>
        </ul>
      </li>
      <li><code><strong>kubevirt</strong></code>
        <ul>
          <li>Provides additional logic to back up and restore virtual machines and other OpenShift Virtualization resources.</li>
        </ul>
      </li>
      <li><code><strong>csi</strong></code>
        <ul>
          <li>Provides volume snapshot support by using the Kubernetes CSI Snapshot API.</li>
        </ul>
      </li>
      <li>third-party plug-ins:<ul>
          <li>OpenStack plug-in for object storage on Swift and volume snapshots on Cinder.</li>
          <li>HPE plug-in for volume snapshots on HPE Nimble Storage.</li>
          <li>DigitalOcean plug-in for volume snapshots on DigitalOcean Volumes Block Storage.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>
<h4>OADP API Resources</h4>
<ul>
  <li><code><strong>DataProtectionApplication</strong></code>
    <ul>
      <li>The <code>dataProtectionApplication</code> resource is the configuration for the OADP operator and its components.</li>
    </ul>
  </li>
</ul>
<pre><code class="language-plaintext">apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
metadata:
  name: oadp-backup
  namespace: openshift-adp
spec:
  configuration:
    velero:
      defaultPlugins:
        - aws
        - openshift
        - csi
      defaultSnapshotMoveData: true
    nodeAgent:
      enable: true
      uploaderType: kopia
  backupLocations:
    - velero:
        config:
          profile: "default"
          region: "us-east-1"
        provider: aws
        default: true
        credential:
          key: cloud
          name: cloud-credentials
        objectStorage:
          bucket: my-bucket
          prefix: oadp</code></pre>
<p>&nbsp;</p>
<ul>
  <li><code><strong>BackupStorageLocation</strong></code>
    <ul>
      <li>The OADP operator creates and manages a <code>backupStorageLocation</code> resource for each storage location that is defined in the <code>dataProtectionApplication</code> configuration.</li>
    </ul>
  </li>
  <li><code><strong>VolumeSnapshotLocation</strong></code>
    <ul>
      <li>The OADP operator creates and manages a <code>volumeSnapshotLocation</code> resource for each snapshot location that is defined in the <code>dataProtectionApplication</code> configuration.</li>
    </ul>
  </li>
  <li><code><strong>Backup</strong></code>
    <ul>
      <li>The <code>backup</code> resource requests the Velero server to create a backup.</li>
    </ul>
  </li>
  <li><code><strong>Restore</strong></code>
    <ul>
      <li>The <code>restore</code> resource requests the Velero server to restore a backup.</li>
    </ul>
  </li>
  <li><code><strong>Schedule</strong></code>
    <ul>
      <li>The <code>schedule</code> resource creates a backup periodically on a given schedule by using the Cron format.</li>
    </ul>
  </li>
  <li><code><strong>BackupRepository</strong></code>
    <ul>
      <li>The <code>BackupRepository</code> resource tracks the lifecycle of the backup repositories.</li>
    </ul>
  </li>
</ul>
<h4>Requirements for OADP</h4>
<ul>
  <li>OpenShift User Permissions: cluster-admin in the openshift-adp namespace</li>
  <li>Object Storage: OADP requires an object storage location to store the backups.</li>
  <li>CSI Snapshot: a volume snapshot class must be created to register the CSI driver to use to create snapshots. The driver name must be the same as the <code>provisioner</code> attribute of the volume storage class to back up.</li>
</ul>
<blockquote>
  <p>For storage classes that do not support snapshots, such as <code>nfs-storage</code>, you can use the file-system backup.</p>
</blockquote>
<p>&nbsp;</p>
<h4>Components Configuration</h4>
<pre><code class="language-plaintext">  configuration:
    velero:
      defaultPlugins: 1
        - aws
        - openshift
        - csi
      defaultSnapShotMoveData: true 2
    nodeAgent: 3
      enable: true 4
      uploaderType: kopia 5
      podConfig: 6
        resourceAllocations:
          limits:
            cpu: "1"
            memory: 8Gi
          requests:
            cpu: 500m
            memory: 256Mi
1. Velero plug-ins to enable. The openshift plug-in is mandatory. The csi plug-in is necessary for
 snapshots and Data Mover.
2. 
Set this parameter to true to use the default Data Mover.

3. The agent that manages volume backups.

4. 
Enable the node agent if you use either FSB or Data Mover.

5. 
You can use either Kopia or Restic as the uploader. If you use the Data Mover, then you must 

use Kopia.

6. 
Optional pod configuration such as node selector, labels, and resource allocation for 

each component.</code></pre>
<h4>Backup Storage Location</h4>
<pre><code class="language-plaintext">  backupLocations:
    - velero:
        config: 1
          profile: "default" 2
          region: "us-east-1"
          s3Url: https://s3.openshift-storage.svc
          s3ForcePathStyle: "true"
          insecureSkipTLSVerify: "true"
        provider: aws 3
        default: true 4
        credential: 5
          key: cloud
          name: cloud-credentials
        objectStorage:
          bucket: my-bucket 6
          prefix: oadp 7
          caCert: LLS0S0...LS0tLS0K 8
1. 
Storage provider-specific configuration. In this example, the configuration is for the aws provider.

2. 
The credentials profile name that is defined in the Velero secret.

3. 
The storage provider plug-in name.

4. 
Use this backup location as the default one if none is specified in the backup and restore resources.

5. 
Velero secret with the storage provider credentials.

6. 
Bucket name from the storage provider.

7. Optional subdirectory in the bucket to store backups. If not specified, then the backups are stored at the root level of the bucket.

8. 
Optional CA bundle in Base64 format to verify TLS connections to the storage provider.</code></pre>
<p>&nbsp;</p>
<blockquote>
  <p>OADP can access the S3 endpoint by using two addressing models:</p>
  <ul>
    <li>The path-style model, such as <code>https://s3.mydomain.com/<i>bucket-name</i>/myfile.txt</code></li>
    <li>The DNS-style model (also known as virtual-hosted style), such as <code>\https://<i>bucket-name</i>.s3.mydomain.com/myfile.txt</code> This method is the default.</li>
  </ul>
  <p>If the object storage solution does not support the DNS-style method, then you can configure OADP to use the path-style model instead with the <code>s3ForcePathStyle</code> option.</p>
</blockquote>
<blockquote>
  <p>ImageStream backup does not work with the <code>caCert</code> option. If the S3 endpoint certificate is not trusted, then the <code>insecureSkipTLSVerify</code> attribute is required to back up container images.</p>
</blockquote>
<ul>
  <li>The Velero secret contains the credentials to access the object storage. If the secret name is not specified in the configuration, then Velero uses the <code>cloud-credentials</code> default secret name.</li>
</ul>
<pre><code class="language-plaintext"> cat credentials-velero
[myProfile] 
aws_access_key_id=AWS_ACCESS_KEY_ID
aws_secret_access_key=AWS_SECRET_ACCESS_KEY</code></pre>
<p>&nbsp;</p>
<ul>
  <li>To get the Ca.crt of the <code>s3.openshift-storage.svc</code>host</li>
</ul>
<pre><code class="language-plaintext"> oc get cm/openshift-service-ca.crt \
  -o jsonpath='{.data.service-ca\.crt}' | base64 -w0; echo</code></pre>
<p>&nbsp;</p>
<pre><code class="language-plaintext">oc create secret generic cloud-credentials \
  --from-file cloud=credentials-velero</code></pre>
<p>&nbsp;</p>
<blockquote>
  <p>The Velero secret must be created before the <code>DataProtectionApplication</code> object, or the installation will fail.</p>
</blockquote>
<h4>Snapshot Storage Location</h4>
<ul>
  <li>The <code>snapshotLocations</code> section describes the storage configuration to use for volume snapshots when using the cloud provider native snapshot capability. For CSI snapshots, this section is not needed, because volume snapshot classes are used instead.</li>
  <li>With Data Mover and FSB, backups are stored in the defined object storage location in the <code>backupLocations</code> section.</li>
</ul>
<pre><code class="language-plaintext">  snapshotLocations:
    - name: default
      velero:
        provider: aws
        config:
          region: us-west-2 1
          profile: "default" 2
        credential: 3
          key: cloud
          name: cloud-credentials
1. AWS region to use to create the snapshots.

2. The credentials profile name that is defined in the Velero secret.

3. Optional: Velero secret with the storage provider credentials.

</code></pre>
<p>&nbsp;</p>
<h4>CSI Snapshots</h4>
<ul>
  <li>For OADP to use a volume snapshot class, you must add the <code>velero.io/csi-volumesnapshot-class: "true"</code> label. <mark class="marker-yellow">Only one volume snapshot class per driver needs this label.</mark></li>
</ul>
<pre><code class="language-plaintext">oc label volumesnapshotclass my-snapshot-storageclass \
  velero.io/csi-volumesnapshot-class="true"</code></pre>
<pre><code class="language-plaintext">oc label volumesnapshotclass \
  velero.io/csi-volumesnapshot-class="true" --all</code></pre>
<h3>Verification and Troubleshooting</h3>
<ul>
  <li>The OADP operator creates and validates each backup storage location that is defined in the <code>DataProtectionApplication</code> object. OADP tries to connect to the object storage with the provided credentials and validates the configuration. If the configuration is correct, then the backup storage location enters the <code>Available</code> phase.</li>
</ul>
<pre><code class="language-plaintext">oc -n openshift-adp get backupstoragelocation</code></pre>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h2>Backup and Restore with OADP</h2>
<ul>
  <li>Backup and restore are initiated by creating the corresponding Kubernetes resources in the <code>openshift-adp</code> namespace.</li>
  <li>Administrative access to the <code>openshift-adp</code> namespace, or to the <code>cluster-admin</code> role, is required to create those resources.</li>
  <li><strong>Backup: </strong>This resource defines the namespaces and resources to include in the backup, and can also include a list of commands to run before or after the backup.<ul>
      <li>The<mark class="marker-yellow"> backup resource definition </mark>and the backup information, such as <mark class="marker-yellow">backup logs and the list of included backup resources</mark>, are<mark class="marker-yellow"> stored in the object storage with the backup.</mark></li>
      <li>OADP <mark class="marker-yellow">synchronizes backup definitions between the object storage and the OpenShift cluster to enable restoring backups to a different cluster with the same backup storage location.</mark></li>
      <li>If a backup resource exists in the OpenShift cluster but is deleted from the object storage, then <mark class="marker-yellow">OADP deletes the Kubernetes resource.</mark></li>
      <li>if a backup exists in the object storage, but not in OpenShift, then OADP<mark class="marker-yellow"> creates the matching backup resource in the cluster.</mark></li>
    </ul>
  </li>
</ul>
<blockquote>
  <p>Only backups with a <code>Completed</code> state are synchronized. The object storage synchronization does not automatically create or remove backup resources with a <code>Failed</code> or <code>PartiallyFailed</code> state.</p>
</blockquote>
<ul>
  <li><strong>Restore: </strong>The <code>restore</code> resource starts restoring an existing backup resource. The restore result, the list of restored resources, and the restore logs are stored in the object storage.</li>
  <li><strong>Schedule: </strong>The <code>schedule</code> resource starts a backup on a given schedule that is written in Cron format.<ul>
      <li>A schedule defines a backup template to create a backup resource at a recurring interval.</li>
    </ul>
  </li>
</ul>
<p>&nbsp;</p>
<figure class="image image_resized" style="width:100%;"><img src="/oadp_backup_snapshot.svg"></figure>
<figure class="table">
  <table style="background-color:rgb(255, 255, 255);">
    <tbody>
      <tr>
        <td style="padding:0px;vertical-align:top;">
          <figure class="image image_resized" style="width:22px;"><img src="https://rol.redhat.com/rol/static/roc/Common_Content/images/1.svg" alt="1"></figure>
        </td>
        <td style="padding:0px;vertical-align:top;">The administrator creates a backup resource in the <code>openshift-adp</code> namespace, which triggers the backup process.</td>
      </tr>
      <tr>
        <td style="padding:0px;vertical-align:top;">
          <figure class="image image_resized" style="width:22px;"><img src="https://rol.redhat.com/rol/static/roc/Common_Content/images/2.svg" alt="2"></figure>
        </td>
        <td style="padding:0px;vertical-align:top;">Velero exports all Kubernetes resources from the application namespace to the backup storage location.</td>
      </tr>
      <tr>
        <td style="padding:0px;vertical-align:top;">
          <figure class="image image_resized" style="width:22px;"><img src="https://rol.redhat.com/rol/static/roc/Common_Content/images/3.svg" alt="3"></figure>
        </td>
        <td style="padding:0px;vertical-align:top;">The Velero CSI plug-in creates a CSI snapshot of the application volume.</td>
      </tr>
      <tr>
        <td style="padding:0px;vertical-align:top;">
          <figure class="image image_resized" style="width:22px;"><img src="https://rol.redhat.com/rol/static/roc/Common_Content/images/4.svg" alt="4"></figure>
        </td>
        <td style="padding:0px;vertical-align:top;">Data Mover clones the <code>volumeSnapshotContent</code> and <code>volumeSnapshot</code> resources to the <code>openshift-adp</code> namespace.</td>
      </tr>
      <tr>
        <td style="padding:0px;vertical-align:top;">
          <figure class="image image_resized" style="width:22px;"><img src="https://rol.redhat.com/rol/static/roc/Common_Content/images/5.svg" alt="5"></figure>
        </td>
        <td style="padding:0px;vertical-align:top;">Data Mover creates a PVC from the volume snapshot.</td>
      </tr>
      <tr>
        <td style="padding:0px;vertical-align:top;">
          <figure class="image image_resized" style="width:22px;"><img src="https://rol.redhat.com/rol/static/roc/Common_Content/images/6.svg" alt="6"></figure>
        </td>
        <td style="padding:0px;vertical-align:top;">Data Mover uses Kopia to transfer the volume data to the backup storage location.</td>
      </tr>
      <tr>
        <td style="padding:0px;vertical-align:top;">
          <figure class="image image_resized" style="width:22px;"><img src="https://rol.redhat.com/rol/static/roc/Common_Content/images/7.svg" alt="7"></figure>
        </td>
        <td style="padding:0px;vertical-align:top;">After the backup completes, Data Mover deletes all volume snapshots and the PVCs that were created during the backup process.</td>
      </tr>
    </tbody>
  </table>
</figure>
<figure class="image image_resized" style="width:100%;"><img src="/oadp_restore_snapshot.svg"></figure>
<figure class="table">
  <table style="background-color:rgb(255, 255, 255);">
    <tbody>
      <tr>
        <td style="padding:0px;vertical-align:top;">
          <figure class="image image_resized" style="width:22px;"><img src="https://rol.redhat.com/rol/static/roc/Common_Content/images/1.svg" alt="1"></figure>
        </td>
        <td style="padding:0px;vertical-align:top;">The administrator creates a restore resource in the <code>openshift-adp</code> namespace, which triggers the restore process.</td>
      </tr>
      <tr>
        <td style="padding:0px;vertical-align:top;">
          <figure class="image image_resized" style="width:22px;"><img src="https://rol.redhat.com/rol/static/roc/Common_Content/images/2.svg" alt="2"></figure>
        </td>
        <td style="padding:0px;vertical-align:top;">Velero imports the Kubernetes resources from the backup storage location to the application namespace.</td>
      </tr>
      <tr>
        <td style="padding:0px;vertical-align:top;">
          <figure class="image image_resized" style="width:22px;"><img src="https://rol.redhat.com/rol/static/roc/Common_Content/images/3.svg" alt="3"></figure>
        </td>
        <td style="padding:0px;vertical-align:top;">Data Mover creates a temporary PVC in the <code>openshift-adp</code> namespace, and transfers the application data from the backup storage location to the new volume.</td>
      </tr>
      <tr>
        <td style="padding:0px;vertical-align:top;">
          <figure class="image image_resized" style="width:22px;"><img src="https://rol.redhat.com/rol/static/roc/Common_Content/images/4.svg" alt="4"></figure>
        </td>
        <td style="padding:0px;vertical-align:top;">Velero creates the PVC in the application namespace with the same PV as the one that Data Mover is restoring. The PVC stays in the pending state until Data Mover completes the restore.</td>
      </tr>
      <tr>
        <td style="padding:0px;vertical-align:top;">
          <figure class="image image_resized" style="width:22px;"><img src="https://rol.redhat.com/rol/static/roc/Common_Content/images/5.svg" alt="5"></figure>
        </td>
        <td style="padding:0px;vertical-align:top;">After the transfer is complete, Data Mover releases the PV from the temporary PVC in the <code>openshift-adp</code> namespace, and binds that PV to the final PVC in the application namespace.</td>
      </tr>
    </tbody>
  </table>
</figure>
<p>&nbsp;</p>
<p>&nbsp;backup examples:</p>
<pre><code class="language-plaintext">apiVersion: velero.io/v1
kind: Backup
metadata:
  name: my-app-backup 
  namespace: openshift-adp
spec:
  includedNamespaces: 
  - my-app-project
  ttl: 720h0m0s  
  labelSelector:
    matchLabels: 
      app: my-app
  includedResources: 
  - deployments
  - configmaps
  - secrets
  - services
  - routes</code></pre>
<p>&nbsp;</p>
<pre><code class="language-plaintext">apiVersion: velero.io/v1
kind: Backup
metadata:
  name: website
  namespace: openshift-adp
spec:
  includedNamespaces:
  - website
  labelSelector:
    matchLabels:
      app: hugo
  includedResources:
  - imagestreams
  - buildconfigs
  - deployments
  - services
  - routes</code></pre>
<p>&nbsp;</p>
<pre><code class="language-plaintext">oc -n openshift-adp describe backup/website
Status:
  Backup Item Operations Attempted:  1
  Backup Item Operations Completed:  1
  Completion Timestamp:              2023-12-11T14:01:42Z 1
  Expiration:                        2024-01-10T14:01:27Z 2
  Format Version:                    1.1.0
  Phase:                             Completed 3
  Progress: 4
    Items Backed Up:     7
    Total Items:         7
  Start Timestamp:       2023-12-11T14:01:27Z 5
  Version:               1
  
1. 
Backup completion time.

2. 
Backup expiration date, which is set with the ttl setting. The backup is automatically removed 

from both the OpenShift cluster and the object storage after this date.

3. 
Status of the backup.

4. 
The backup progress, with the number of backed up items so far and the total items to back up.
5. 
Backup start time.</code></pre>
<p>&nbsp;</p>
<ul>
  <li>The backup resource can have the following statuses during its lifetime:<ol>
      <li><strong>New</strong>
        <ul>
          <li>Initial status when a backup is created. <mark class="marker-yellow">If the backup definition is incorrect, then the backup is aborted and its status changes to </mark><code><mark class="marker-yellow">FailedValidation</mark></code>. You can review the <code>validationErrors</code> status field for more information about the error.</li>
          <li><mark class="marker-yellow">If the backup definition is valid, then the status changes to </mark><code><mark class="marker-yellow">InProgress</mark></code><mark class="marker-yellow">.</mark></li>
        </ul>
      </li>
      <li><strong>InProgress</strong>
        <ul>
          <li>Status when the backup is in progress. <mark class="marker-yellow">During this phase, OADP backs up the resources that are specified in the backup definition and runs the backup hooks.</mark></li>
          <li>When OADP uses <mark class="marker-yellow">additional plug-ins</mark>, such as OADP Data Mover, the backup enters the <code>WaitingForPluginOperations</code> status. After the plug-in processes are complete, the backup enters the <code>Finalizing</code> status where OADP<mark class="marker-yellow"> saves all the remaining backup items, such as backup logs and metadata, to the object storage.</mark></li>
          <li>If backing up some resources fails, then the status changes in turn to <code>WaitingForPluginOperationsPartiallyFailed</code>, <code>FinalizingPartiallyFailed</code>, and then <code>PartiallyFailed</code>.</li>
        </ul>
      </li>
      <li><strong>PartiallyFailed and Failed</strong>
        <ul>
          <li>The final status of a backup, wit<mark class="marker-yellow">h some missing resources because of a backup failure</mark>. A partially failed backup can still restore a project, but incompletely. A backup with the <code>Failed</code> status cannot be restored.</li>
          <li>You can review the <code>failureReason</code> status field for more information about the error.</li>
        </ul>
      </li>
      <li><strong>Completed</strong>
        <ul>
          <li>Final status of a successfully completed backup. All the data is in the object storage and the backup is ready to use in a restore.</li>
        </ul>
      </li>
    </ol>
  </li>
</ul>
<p>Restore examples:</p>
<pre><code class="language-plaintext">apiVersion: velero.io/v1
kind: Restore
metadata:
  name: restore-name 1
  namespace: openshift-adp
spec:
  backupName: backup-name 2
  
1. Name of the restore resource


2. Name of the backup resource to restore</code></pre>
<p>&nbsp;</p>
<blockquote>
  <p>OADP restores only the resources that are not already in the destination namespace. The destination namespace is the same as in the backup, unless you use the <code>namespaceMapping</code> field to specify a different namespace.</p>
</blockquote>
<pre><code class="language-plaintext">apiVersion: velero.io/v1
kind: Restore
metadata:
  name: website-stage
  namespace: openshift-adp
spec:
  backupName: website
  namespaceMapping:
    website: website-stage</code></pre>
<p>&nbsp;</p>
<pre><code class="language-plaintext">

[user@host ~]$ oc -n openshift-adp describe restore/website-stage
Name:         website-stage
Namespace:    openshift-adp
...output omitted...
Spec:
  Backup Name:  website
  Excluded Resources: 1
    nodes
    events
    events.events.k8s.io
    backups.velero.io
    restores.velero.io
    resticrepositories.velero.io
    csinodes.storage.k8s.io
    volumeattachments.storage.k8s.io
    backuprepositories.velero.io
  Item Operation Timeout:  1h0m0s
  Namespace Mapping:
    Website:  website-stage
Status:
  Completion Timestamp:  2023-12-12T09:36:23Z 2
  Phase:                 Completed 3
  Progress: 4
    Items Restored:                   7
    Total Items:                      7
  Restore Item Operations Attempted:  1
  Restore Item Operations Completed:  1
  Start Timestamp:                    2023-12-12T09:36:14Z 5
1. 
OADP automatically excludes some resources from the restore, such as Kubernetes events and OADP custom resources. You can modify this list with the excludedResources field in the restore definition.

2. 
Restore completion time.

3. 
Status of the restore.

4. 
The restore progress, with the number of restored items so far and the total items to restore.

5. 
Restore start time.</code></pre>
<p>&nbsp;</p>
<blockquote>
  <p>The possible statuses of the restore are the same as for the backup resource. A successful restore goes through the following statuses during its lifetime:</p>
  <p><code>New</code></p>
  <p><code>InProgress</code></p>
  <p><code>WaitingForPluginOperations</code></p>
  <p><code>Completed</code></p>
</blockquote>
<ul>
  <li>During the restore, OADP adds two labels to the imported resources: A <code>velero.io/restore-name</code> label with the restore name, and a <code>velero.io/backup-name</code> with the backup name that the resource came from.</li>
  <li>OADP stores in the object storage detailed information about each backup and restore attempt, such as logs, the list of resources that are backed up or restored, and a summary of the errors or warnings that occur during the backup and restore process.</li>
</ul>
<pre><code class="language-plaintext">s3
├── docker 1
│   └── registry
│       └── v2
│           ├── blobs
│           └── repositories
│               └── website
│                   └── hugo
└── oadp
    ├── backups 2
    │   └── website
    │       ├── website-logs.gz
    │       ├── website-results.gz
    │       └── website.tar.gz
    └── restores 3
        └── website-stage
            ├── restore-website-stage-logs.gz
            └── restore-website-stage-results.gz
1. 
The /docker/registry/v2 path contains a Docker registry with the container images that are 
included in all backups.

2. 
The /oadp/backups path contains all the information about each backup, including the backed-up 

Kubernetes resources and the backup logs. Each subdirectory is unique to a single backup attempt 

and relates to the matching backup resource in the cluster.

3. 
The /oadp/restores path contains all the information about each restore, including the restore 

logs. Each subdirectory is unique to a single restore attempt and relates to the matching restore 

resource in the cluster.</code></pre>
<p>&nbsp;</p>
<h4>Introducing the Velero Tool</h4>
<ul>
  <li>OADP provides the <code>velero</code> command-line tool that can retrieve backup and restore information from both the object storage and the OpenShift cluster.</li>
</ul>
<pre><code class="language-plaintext">alias velero='\
  oc -n openshift-adp exec deployment/velero -c velero -it -- ./velero'</code></pre>
<p>&nbsp;</p>
<ul>
  <li>The <code>velero</code> command can use the same syntax as the <code>kubectl</code> or <code>oc</code> commands, but is limited to OADP Kubernetes custom resources such as the <code>backup</code>, <code>restore</code>, and <code>schedule</code> resources.</li>
</ul>
<pre><code class="language-plaintext">velero get resource
velero describe resource/name --details</code></pre>
<p>&nbsp;</p>
<pre><code class="language-plaintext">[user@host ~]$ velero describe backup website --details
Name:         website
Namespace:    openshift-adp
...output omitted...

Phase:  Completed 

Namespaces: 
  Included:  website
  Excluded:  &lt;none&gt;

Resources:
  Included:        imagestreams, buildconfigs, deployments, services, routes
  Excluded:        &lt;none&gt;
  Cluster-scoped:  auto

Label selector:  app=hugo

...output omitted...

Started:    2023-12-11 14:01:27 +0000 UTC
Completed:  2023-12-11 14:01:42 +0000 UTC

Expiration: 2024-01-10 14:01:27 +0000 UTC

Total items to be backed up:  7
Items backed up:              7

Resource List: 
  apps/v1/Deployment:
    - website/hugo
  build.openshift.io/v1/BuildConfig:
    - website/hugo
  image.openshift.io/v1/ImageStream:
    - website/hugo
    - website/nginx-122
  route.openshift.io/v1/Route:
    - website/hugo
  v1/Service:
    - website/hugo

Velero-Native Snapshots: &lt;none included&gt;</code></pre>
<p>&nbsp;</p>
<pre><code class="language-plaintext"> velero create restore website-dev \
  --from-backup=website-label --namespace-mappings=website:website-dev</code></pre>
<p>&nbsp;</p>
<blockquote>
  <p>Avoid including resources that other resources manage, such as builds, endpoints, or replica sets. It is unnecessary and can cause issues during the restore. You must filter to include in the backup only those resources that your application requires for a successful deployment.</p>
</blockquote>
<h4>Backing up a Stateful Application with Backup Hooks</h4>
<ul>
  <li>OADP creates crash-consistent backups of your application by using volume snapshots. To back up persistent volumes, you <mark class="marker-yellow">must include</mark> the <code>persistentvolumeclaims</code> and <code>persistentvolumes</code> resource types in the <mark class="marker-yellow">backup definition.</mark></li>
</ul>
<blockquote>
  <p><mark class="marker-pink">OpenShift assigns to each namespace a unique UID and GID that the application pod uses to write data to persistent volumes. If you restore an application to a new namespace, then OpenShift assigns a new set of UIDs and GIDs that prevent the application from accessing its data.So that OADP can restore the UID and GID, include the </mark><code><mark class="marker-pink">namespace</mark></code><mark class="marker-pink"> resource type in the backup definition. If you use a label selector in the backup definition, then you must add the corresponding label to the namespace. Alternatively, you can use the </mark><code><mark class="marker-pink">kubernetes.io/metadata.name</mark></code><mark class="marker-pink"> label that Kubernetes automatically sets on all namespaces.</mark></p>
</blockquote>
<ul>
  <li>use backup hooks to specify a list of commands to execute in the application pod before and after the backup is created. You can then use those hooks to quiesce the application and perform an application-consistent backup.</li>
  <li>To configure backup hooks, you must specify the target pod (by using labels), the container name, and the commands to run on that container.</li>
  <li><strong>Pre backup hooks</strong>
    <ul>
      <li>A <code>pre</code> backup hook is<mark class="marker-yellow"> executed before any other backup action on the pod. </mark>If the command fails, then the backup stops immediately with the <code>Failed</code> status.</li>
      <li>As an example, you can use this type of hook to quiesce and prepare the application for backup.</li>
    </ul>
  </li>
  <li><strong>Post backup hooks</strong>
    <ul>
      <li>A <code>post</code> backup hook is<mark class="marker-yellow"> executed after the backup of the pod and its attached volumes. </mark>If the command fails, then the backup stops immediately with the <code>PartiallyFailed</code> status.</li>
      <li>As an example, you can use this type of hook to resume or unlock the application after the backup is complete.</li>
    </ul>
  </li>
  <li><strong>Init restore hooks</strong>
    <ul>
      <li>An <code>init</code> restore hook is<mark class="marker-yellow"> executed after the pod and its attached volumes are restored,</mark> but<mark class="marker-yellow"> before any container on that pod starts</mark>. The <code>init</code> restore hook <mark class="marker-yellow">defines one or more init containers that follow the same specification as the init container in a pod definition.</mark></li>
      <li>OADP does not monitor the status of the init container. Therefore, if the command fails, then the <mark class="marker-yellow">restore continues without any error or warning</mark>, but the application pod is in error with the <code>Init:Error</code> status.</li>
      <li>As an example, you can use this type of hook to restore a database that the application requires and that is external to the OpenShift cluster.</li>
    </ul>
  </li>
  <li><strong>Post restore hooks</strong>
    <ul>
      <li>A <code>post</code> restore hook is executed <mark class="marker-yellow">when the application pod is restored and running. </mark>If the command fails, then <mark class="marker-yellow">the error is logged and the restore continues.</mark></li>
      <li>As an example, you can use this type of hook to run an integrity check on the restored database.</li>
    </ul>
  </li>
</ul>
<pre><code class="language-plaintext">apiVersion: velero.io/v1
kind: Backup
metadata:
  name: mongodb
  namespace: openshift-adp
spec:
  includedNamespaces:
  - mongodb
  orLabelSelectors: 1
  - matchLabels:
      app: mongodb
  - matchLabels:
      kubernetes.io/metadata.name: mongodb
  includedResources: 2
  - deployments
  - services
  - secret
  - pvc
  - pv
  - pods
  - namespace
  hooks:
    resources:
    - name: mongodb-lock
      labelSelector: 3
        matchLabels:
          app: mongodb
      pre: 4
      - exec:
          container: mongodb
          command:
          - /usr/bin/mongosh
          - --eval
          - db.fsyncLock();
      post: 5
      - exec:
          container: mongodb
          command:
          - /usr/bin/mongosh
          - --eval
          - db.fsyncUnlock();
1. 
Resources with the app: mongodb or kubernetes.io/metadata.name: mongodb label are included in 
the backup.

2. 
The pvc and pv resource types must be specified in the includedResources key to back up the 

application volume. The pods resource type must also be specified for the backup hooks to be executed. The namespace resource type must be specified to preserve the UID and GID that are used in the application volume.

3. 
The hook runs on all pods that match the label selector.

4. 
The pre backup hook executes the db.fsyncLock() MongoDB command in the mongodb container to 

lock the database before the volume snapshot.

5. 
The post backup hook executes the db.fsyncUnlock() MongoDB command to unlock the database 

after the backup is completed.</code></pre>
<p>&nbsp;</p>
<pre><code class="language-plaintext">apiVersion: velero.io/v1
kind: Restore
metadata:
  name: mongodb
  namespace: openshift-adp
spec:
  backupName: mongodb
  hooks:
    resources:
    - name: mongodb-unlock
      labelSelector:
        matchLabels:
          app: mongodb
      postHooks:
      - init: 1
          initContainers:
          - name: remove-lock
            image: mongodb/mongodb-community-server:7.0-ubi8
            volumeMounts:
            - name: mongodb-data
              mountPath: /data/db
            command:
            - /usr/bin/rm
            - /data/db/mongod.lock
1. The init restore hook removes the database lock from the backup before the database starts.

</code></pre>
<p>&nbsp;</p>
<ul>
  <li>OADP Data Mover stores the volume backup in the object storage inside a Kopia unified repository.<ul>
      <li>Kopia encrypts, deduplicates, and compresses the data in the backup repository.</li>
      <li>OADP uses a dedicated backup repository for each namespace to store all volume backups for that namespace.</li>
      <li>OADP uses this unified repository to store backups from both volume snapshots and file-system backups.</li>
      <li>When the first backup of a namespace is created, OADP<mark class="marker-yellow"> initializes a Kopia repository in the object storage</mark>, and creates a matching <code>BackupRepository</code> resource in the <code>openshift-adp</code> namespace.</li>
    </ul>
  </li>
</ul>
<pre><code class="language-plaintext">s3
└── oadp
    ├── backups
    │   └── mongodb
    │       ├── mongodb-logs.gz
    │       └── ...
    ├── kopia 1
    │   └── mongodb
    │       ├── kopia.repository
    │       └── ...
    └── restores
        └── mongodb
            ├── restore-mongodb-logs.gz
            └── ...
1.
The /oadp/kopia path contains the backup repositories with data from volume backups. Each 
subdirectory is a unique Kopia repository for a single namespace in the cluster and contains 
all backups from all volumes in that namespace.</code></pre>
<p>&nbsp;</p>
<h3>Scheduling a Recurring Backup</h3>
<pre><code class="language-plaintext">apiVersion: velero.io/v1
kind: Schedule
metadata:
  name: website-daily
  namespace: openshift-adp
  labels: 1
    app: hugo
spec:
  schedule: "0 7 * * *" 2
  paused: false 3
  template: 4
    includedNamespaces:
    - website
    labelSelector:
      matchLabels:
        app: hugo
    includedResources:
    - imagestreams
    - buildconfigs
    - deployments
    - services
    - routes
    ttl: 720h0m0s
1. 
The labels that you set on the schedule resource are automatically copied to the 
backup resources that the schedule creates.

2. 
Specifies the schedule for the job in Cron format.

3. 
You can disable the schedule by setting the paused parameter to true.

4. 
Sets the backup definition template by using the same settings as in a backup resource.</code></pre>
<p>&nbsp;</p>
<pre><code class="language-plaintext">velero get schedule</code></pre>
<p>&nbsp;</p>
<ul>
  <li>The status of an activated schedule is <code>Enabled</code>. If the schedule is disabled with the <code>paused</code> parameter, then its status is <code>New</code>. The <code>LAST BACKUP</code> column shows the time of the latest backup that the schedule created.</li>
  <li>To back up an application on demand, you can create a disabled schedule as a backup template. You can then start a new backup with this schedule when you need it.</li>
</ul>
<pre><code class="language-plaintext">velero create backup pre-upgrade-1.1 \
  --from-schedule website-daily</code></pre>
<p>&nbsp;</p>
<ul>
  <li>Backup resources that are created from a schedule inherit the schedule's labels. In addition, the <code>velero.io/schedule-name</code> label is set on the backup resources with the schedule name.</li>
</ul>
<h3>Cleaning Backups</h3>
<ul>
  <li>OADP automatically re-creates any backup that you delete with the <code>oc</code> command. To permanently delete a backup, you must delete it from the object storage.</li>
  <li>Use the <code>velero</code> command to delete backup and restore information from the object storage, and all the associated resources from the cluster:</li>
</ul>
<pre><code class="language-plaintext"> velero delete backup backup-name</code></pre>
<p>&nbsp;</p>
<ul>
  <li>The backup status changes to <code>Deleting</code>, and OADP removes all restore resources that are attached to this backup from both the OpenShift cluster and the object storage. Then the backup itself is removed from the cluster and the object storage.</li>
  <li>By default, OADP deletes backups after 30 days. The minimum lifetime of a backup is 1 hour.</li>
</ul>
<blockquote>
  <p>OADP does not immediately delete data from the backup repository on the object storage. OADP occasionally runs repository maintenance, such as to delete data that backups no longer need. OADP might start deleting data from the object storage up to 24 hours after a backup is deleted.</p>
</blockquote>
<h3>Backing up Volumes with File System Backup</h3>
<figure class="image image_resized" style="width:100%;"><img src="/oadp_backup_restic.svg"></figure>
<figure class="table">
  <table style="background-color:rgb(255, 255, 255);">
    <tbody>
      <tr>
        <td style="padding:0px;vertical-align:top;">
          <figure class="image image_resized" style="width:22px;"><img src="https://rol.redhat.com/rol/static/roc/Common_Content/images/1.svg" alt="1"></figure>
        </td>
        <td style="padding:0px;vertical-align:top;">The administrator creates a backup resource in the <code>openshift-adp</code> namespace that triggers the backup process.</td>
      </tr>
      <tr>
        <td style="padding:0px;vertical-align:top;">
          <figure class="image image_resized" style="width:22px;"><img src="https://rol.redhat.com/rol/static/roc/Common_Content/images/2.svg" alt="2"></figure>
        </td>
        <td style="padding:0px;vertical-align:top;">Velero exports all Kubernetes resources from the application namespace to the backup storage location.</td>
      </tr>
      <tr>
        <td style="padding:0px;vertical-align:top;">
          <figure class="image image_resized" style="width:22px;"><img src="https://rol.redhat.com/rol/static/roc/Common_Content/images/3.svg" alt="3"></figure>
        </td>
        <td style="padding:0px;vertical-align:top;">The <code>node-agent</code> daemon set, which runs on the same node as the application pod, exports the volume data from the volume mount point on the cluster node to the backup storage location.</td>
      </tr>
    </tbody>
  </table>
</figure>
<p>&nbsp;</p>
<figure class="image image_resized" style="width:100%;"><img src="/oadp_restore_restic.svg"></figure>
<figure class="table">
  <table style="background-color:rgb(255, 255, 255);">
    <tbody>
      <tr>
        <td style="padding:0px;vertical-align:top;">
          <figure class="image image_resized" style="width:22px;"><img src="https://rol.redhat.com/rol/static/roc/Common_Content/images/1.svg" alt="1"></figure>
        </td>
        <td style="padding:0px;vertical-align:top;">The administrator creates a restore resource in the <code>openshift-adp</code> namespace, which triggers the restore process.</td>
      </tr>
      <tr>
        <td style="padding:0px;vertical-align:top;">
          <figure class="image image_resized" style="width:22px;"><img src="https://rol.redhat.com/rol/static/roc/Common_Content/images/2.svg" alt="2"></figure>
        </td>
        <td style="padding:0px;vertical-align:top;">Velero imports the Kubernetes resources from the backup storage location to the application namespace.</td>
      </tr>
      <tr>
        <td style="padding:0px;vertical-align:top;">
          <figure class="image image_resized" style="width:22px;"><img src="https://rol.redhat.com/rol/static/roc/Common_Content/images/3.svg" alt="3"></figure>
        </td>
        <td style="padding:0px;vertical-align:top;">The <code>node-agent</code> daemon set, which runs on the same node as the application pod, imports the application data from the backup storage location to the mount point for the application volume on the cluster node.</td>
      </tr>
    </tbody>
  </table>
</figure>
<p>&nbsp;</p>
<ul>
  <li>You can instruct OADP to back up all volumes in a backup definition with FSB by using the <code>defaultVolumesToFsBackup</code> option:</li>
</ul>
<pre><code class="language-plaintext">apiVersion: velero.io/v1
kind: Backup
metadata:
  name: &lt;backup-name&gt;
  namespace: openshift-adp
spec:
  defaultVolumesToFsBackup: true</code></pre>
<p>&nbsp;</p>
<ul>
  <li>annotate the application pod t<mark class="marker-yellow">o specify which volumes to back up with FSB</mark> by using the <code>backup.velero.io/backup-volumes</code> annotation.<ul>
      <li>OADP backs up the volumes in the annotation with FSB, and all other volumes with snapshots.</li>
    </ul>
  </li>
</ul>
<p>&nbsp;</p>
<pre><code class="language-plaintext">apiVersion: apps/v1
kind: Deployment
metadata:
  name: website-nginx
  namespace: org-website
spec:
  template:
    metadata:
      annotations:
        backup.velero.io/backup-volumes: wwwdata &gt;&gt; List of volumes to back up with FSB. 
        You must use the same volume name that is defined in the pod definition.


    spec:
      containers:
        name: web
        image: registry.access.redhat.com/ubi9/nginx-120
        ...output omitted...
        volumeMounts:
        - mountPath: /opt/app-root/src
          name: wwwdata
      ...output omitted...
      volumes:
      - name: wwwdata
        persistentVolumeClaim:
          claimName: nginx-wwwdata
...output omitted...</code></pre>
<p>&nbsp;</p>
<blockquote>
  <p>Only volumes that are compatible with volume snapshots are included in the backup by default. You must enable FSB to include volumes in your backup that are not compatible with volume snapshots.</p>
</blockquote>
<h3>Troubleshooting Backups and Restores</h3>
<pre><code class="language-plaintext">velero get backup mybackup

velero describe backup mybackup
Name:         mybackup
Namespace:    openshift-adp
Labels:       velero.io/storage-location=oadp-backup-1
Annotations:  velero.io/source-cluster-k8s-gitversion=v1.25.7+eab9cc9
              velero.io/source-cluster-k8s-major-version=1
              velero.io/source-cluster-k8s-minor-version=25

Phase:  PartiallyFailed (run `velero backup logs mybackup` for more information)

Errors:
  Velero:     &lt;none&gt;
  Cluster:    &lt;none&gt;
  Namespaces:
    database:   resource: /pods name: /mariadb-757c5bdc88-mrwhb error: /command terminated with exit code 1
...output omitted...

velero backup logs mybackup

velero backup logs mybackup | grep hookPhase</code></pre>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
