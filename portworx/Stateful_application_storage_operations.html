<!--
title: Stateful application storage operations
description: 
published: true
date: 2025-11-11T18:52:57.175Z
tags: 
editor: ckeditor
dateCreated: 2025-11-11T17:16:59.056Z
-->

<h1><strong>Stateful application storage operations</strong></h1>
<ul>
  <li>portwox is able to clone applications configuration and data between namespaces in the same cluster or different clusters</li>
</ul>
<blockquote>
  <p>All application storage operations require the <mark class="marker-yellow">administrator-level cluster privileges</mark> if you operate between namespaces</p>
</blockquote>
<ul>
  <li>Main API resources:<ol>
      <li>backupLocation</li>
      <li>applicationBackup</li>
    </ol>
  </li>
</ul>
<h3>backupLocation</h3>
<ul>
  <li>portworx supports &nbsp;these object storage providers:<ol>
      <li>S3 compatible storage</li>
      <li>Azure blobs</li>
      <li>GCC storage</li>
    </ol>
  </li>
  <li>For S3 storage this data is required:</li>
</ul>
<pre><code class="language-plaintext">"endpoint" : "bucketEndpoint.com"
"key": "ABCDEF1234567890"
"secret": "ABCDEF1234567890ABCDEF1234567890ABCDEF1234567890"</code></pre>
<p>&nbsp;</p>
<blockquote>
  <p>To restore backups to a different cluster, a backupLocation resource must be created on the new cluster that matches the backupLocation CRD on your original cluster.</p>
</blockquote>
<ul>
  <li>There are two methods to provide the required data to connect to a S3 bucket:<ol>
      <li>plaintext in the backupLocation resource</li>
      <li>as a secret</li>
    </ol>
  </li>
</ul>
<h4><strong>Plaintext credentials</strong></h4>
<pre><code class="language-plaintext">apiVersion: stork.libopenstorage.org/v1alpha1
kind: BackupLocation
metadata:
  name: mysql
  namespace: mysql-app
  annotations:
    stork.libopenstorage.org/skipresource: "true"
location:
  type: s3
  path: "bucket-name"
  sync: true
  s3Config:
    region: us-east-1
    accessKeyID: XXXX
    secretAccessKey: XXXX
    endpoint: "https://bucketEndpoint.com"
    disableSSL: false</code></pre>
<p>&nbsp;</p>
<ul>
  <li><strong>name:</strong> the backupLocation object's name</li>
  <li><strong>namespace:</strong> the<mark class="marker-yellow"> namespace the backupLocation exists in</mark></li>
  <li><strong>location:</strong>
    <ul>
      <li><strong>type:</strong> the <mark class="marker-yellow">object store type</mark></li>
      <li><strong>path:</strong> <mark class="marker-yellow">the bucket Portworx will use for the backup</mark></li>
      <li><strong>sync:</strong> If you're<mark class="marker-yellow"> restoring to a new cluster</mark>, set <code>sync</code> to true to allow your new cluster to retrieve the previous backups from your backup location.</li>
      <li><strong>s3Config:</strong>
        <ul>
          <li><strong>region:</strong> which region your s3 bucket is located in</li>
          <li><strong>accessKeyID:</strong> your bucket's accessKeyID</li>
          <li><strong>secretAccessKey:</strong> your bucket's secretAccessKey</li>
          <li><strong>endpoint:</strong> the URL or IP address of your bucket</li>
          <li><strong>disableSSL:</strong> whether or not to disable SSL</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>
<blockquote>
  <p>If you use URL as your bucket endpoint, you must include the http prefix: either <code>https://</code> or <code>http://</code>, depending on whether or not you're using SSL.</p>
</blockquote>
<h4><strong>Kubernetes secret containing your credentials</strong></h4>
<pre><code class="language-plaintext">  apiVersion: v1
  kind: Secret
  metadata:
    name: s3secret
    namespace: mysql
    annotations:
      stork.libopenstorage.org/skipresource: "true" &gt; Annotate the Kubernetes secret so that other 
      components like Stork and PX-Backup do not backup this resource.
  stringData:
    region: us-east-1
    accessKeyID: &lt;access-key&gt;
    secretAccessKey: &lt;secret-key&gt;
    endpoint: "X.X.X.141:9010"
    disableSSL: "false"
    encryptionKey: "testKey"</code></pre>
<ul>
  <li><strong>name:</strong> the Secret object's name</li>
  <li><strong>namespace:</strong> the <mark class="marker-yellow">namespace the Secret exists in</mark></li>
  <li><strong>stringData:</strong>
    <ul>
      <li><strong>region:</strong> which region your s3 bucket is located in</li>
      <li><strong>accessKeyID:</strong> your bucket's accessKeyID</li>
      <li><strong>secretAccessKey:</strong> your bucket's secretAccessKey</li>
      <li><strong>endpoint:</strong> the URL or IP address of your bucket</li>
      <li><strong>disableSSL:</strong> whether or not to disable SSL</li>
      <li><strong>encryptionKey:</strong> your secret's encryption key</li>
    </ul>
  </li>
</ul>
<pre><code class="language-plaintext">apiVersion: stork.libopenstorage.org/v1alpha1
kind: BackupLocation
metadata:
  name: mysql-backup
  namespace: mysql
  annotations:
    stork.libopenstorage.org/skipresource: "true"
location:
  type: s3
  path: "bucket-name"
  secretConfig: s3secret
  sync: true</code></pre>
<ul>
  <li><strong>name:</strong> the backupLocation object's name</li>
  <li><strong>namespace:</strong> the namespace the backupLocation exists in</li>
  <li><strong>location:</strong>
    <ul>
      <li><strong>type:</strong> the object store type</li>
      <li><strong>path:</strong> the bucket Portworx will use for the backup</li>
      <li><strong>secretConfig:</strong> the <mark class="marker-yellow">Secret object containing your bucket's credentials</mark></li>
      <li><strong>sync:</strong> If you're restoring to a new cluster, set <code>sync</code> to true to allow your new cluster to retrieve the previous backups from your backup location.</li>
    </ul>
  </li>
</ul>
<h3><strong>applicationBackup</strong></h3>
<pre><code class="language-plaintext">apiVersion: stork.libopenstorage.org/v1alpha1
kind: ApplicationBackup
metadata:
  name: backup
  namespace: mysql-app
spec:
  backupLocation: mysql
  namespaces:
  - mysql-app
  reclaimPolicy: Delete
  selectors:
  preExecRule:
  postExecRule:</code></pre>
<p>&nbsp;</p>
<ul>
  <li><strong>name:</strong> the applicationBackup object's name</li>
  <li><strong>namespace:</strong><mark class="marker-yellow"> the namespace the applicationBackup exists in</mark></li>
  <li><strong>spec:</strong>
    <ul>
      <li><strong>backupLocation:</strong> what <mark class="marker-yellow">backupLocation object to use to determine where to send the backup</mark></li>
      <li><strong>namespaces:</strong> the <mark class="marker-yellow">namespaces to backup</mark></li>
      <li><strong>reclaimPolicy:</strong> <mark class="marker-yellow">what happens to objects in the object store when the </mark><code><mark class="marker-yellow">ApplicationBackup</mark></code><mark class="marker-yellow"> object is deleted</mark>, either <code>Delete</code> or <code>Retain</code></li>
      <li><strong>selectors:</strong> define <mark class="marker-yellow">specific labels to determine which objects and volumes are backed-up</mark></li>
      <li><strong>preExecRule:</strong> what rule to run before performing backup</li>
      <li><strong>postExecRule:</strong> what rule to run after performing backup</li>
    </ul>
  </li>
</ul>
<pre><code class="language-plaintext">apiVersion: stork.libopenstorage.org/v1alpha1
kind: Rule
metadata:
  name: cassandra-presnap-rule
spec:
  - podSelector:
      app: cassandra
    actions:
    - type: command
      value: nodetool flush</code></pre>
<p>&nbsp;</p>
<pre><code class="language-plaintext">storkctl get applicationbackup -n mysql-app
oc describe applicationbackup.stork.libopenstorage.org -n mysql-app</code></pre>
<h3><strong>ApplicationBackupSchedule</strong></h3>
<pre><code class="language-plaintext">apiVersion: stork.libopenstorage.org/v1alpha1
kind: SchedulePolicy
metadata:
  name: backupSchedule
policy:
  interval:
    intervalMinutes: 60
    retain: 5
  daily:
    time: "10:14PM"
    retain: 5
  weekly:
    day: "Thursday"
    time: "10:13PM"
    retain: 5
  monthly:
    date: 14
    time: "8:05PM"
    retain: 5</code></pre>
<p>&nbsp;</p>
<pre><code class="language-plaintext">storkctl get schedulepolicy</code></pre>
<p>&nbsp;</p>
<pre><code class="language-plaintext">apiVersion: stork.libopenstorage.org/v1alpha1
kind: ApplicationBackupSchedule
metadata:
  name: backup
  namespace: mysql
spec:
  schedulePolicyName: testpolicy
  template:
    spec:
      backupLocation: mysql
      namespaces:
      - mysql
      reclaimPolicy: Delete</code></pre>
<p>&nbsp;</p>
<ul>
  <li><strong>name:</strong> the applicationBackupSchedule object's name</li>
  <li><strong>namespace:</strong> the namespace the applicationBackupSchedule exists in</li>
  <li><strong>spec.schedulePolicyName:</strong> the <mark class="marker-yellow">name of the schedule policy that defines when backup actions happen</mark></li>
  <li><strong>spec.template.spec.backupLocation:</strong> the name of the <mark class="marker-yellow">backup location spec</mark></li>
  <li><strong>spec.template.spec.namespaces:</strong> namespaces which will be backed up</li>
  <li><strong>spec.template.spec.reclaimPolicy:</strong> what happens to objects in the object store when the <code>ApplicationBackup</code> object is deleted</li>
</ul>
<h2><strong>Restore an application</strong></h2>
<blockquote>
  <p>If you're restoring an <mark class="marker-yellow">application across namespaces on OpenShift, you must modify your destination namespace to include the same supplemental group annotation values as your source namespace:</mark></p>
  <pre><code class="language-plaintext">annotations:  openshift.io/sa.scc.mcs: s0:c26,c25  
              openshift.io/sa.scc.supplemental-groups: 1001990000/10000  
              openshift.io/sa.scc.uid-range: 1001990000/10000</code></pre>
</blockquote>
<p>&nbsp;</p>
<pre><code class="language-plaintext">apiVersion: stork.libopenstorage.org/v1alpha1
kind: ApplicationRestore
metadata:
  name: restore
  namespace: mysql-app
spec:
  backupName: backup
  backupLocation: mysql
  namespaceMapping:
    &lt;backup_namespace&gt;: &lt;restore_namespace&gt;
  replacePolicy: Delete</code></pre>
<ul>
  <li><strong>name:</strong> the ApplicationRestore object's name</li>
  <li><strong>namespace:</strong> the ApplicationRestore object's namespace</li>
  <li><strong>spec.backupName:</strong> the name of the <code>applicationBackup</code> object to restore from</li>
  <li><strong>spec.backupLocation:</strong><mark class="marker-yellow"> which backup location object to get application backups from</mark></li>
  <li><strong>spec.namespaceMapping:</strong> <mark class="marker-yellow">a map of source and destination namespaces, </mark>allowing you to restore a backup to a different namespace</li>
  <li><strong>spec.replacePolicy:</strong> specifies whether you want to <mark class="marker-yellow">delete or retain any matching existing resource in the target namespace</mark></li>
</ul>
<pre><code class="language-plaintext">storkctl get applicationbackup -n namespace
storkctl get applicationrestore -n mysql-app</code></pre>
<ul>
  <li>To restore an application to a different cluster<ol>
      <li>On the destination cluster, create BackupLocation CRD.</li>
      <li>From the source cluster, get completed ApplicationBackup CR YAML and save it in a file with command:</li>
    </ol>
  </li>
</ul>
<pre><code class="language-plaintext">oc get ApplicationBackup &lt;Backup-Which-need-to-be-Restored&gt; -oyaml &gt; backup-completed.yaml</code></pre>
<h2><strong>Clone an Application</strong></h2>
<blockquote>
  <p>If you're cloning an application across namespaces on OpenShift, you must modify your destination namespace to include the same supplemental group annotation values as your source namespace:</p>
</blockquote>
<pre><code class="language-plaintext">annotations:  openshift.io/sa.scc.mcs: s0:c26,c25
              openshift.io/sa.scc.supplemental-groups: 1001990000/10000
              openshift.io/sa.scc.uid-range: 1001990000/10000</code></pre>
<p>&nbsp;</p>
<blockquote>
  <p>Distributed apps, such as Cassandra, may use the same node IDs on the destination namespace as their source, causing disruption when the new nodes join the source cluster.</p>
</blockquote>
<pre><code class="language-plaintext">apiVersion: stork.libopenstorage.org/v1alpha1
kind: ApplicationClone
metadata:
  name: clone-mysql
  namespace: kube-system
spec:
  sourceNamespace: mysql-app
  destinationNamespace: clone-mysql</code></pre>
<ul>
  <li><strong>name:</strong> the ApplicationClone object's name</li>
  <li><strong>namespace:</strong> the ApplicationClone object's namespace</li>
  <li><strong>spec.sourceNamespace:</strong> the <mark class="marker-yellow">namespace you want to clone applications </mark><i><mark class="marker-yellow">from</mark></i></li>
  <li><strong>spec.destinationNamespace:</strong> the<mark class="marker-yellow"> namespace you want to clone applications </mark><i><mark class="marker-yellow">to</mark></i></li>
</ul>
<p>&nbsp;</p>
<h2><strong>ApplicationRegistration</strong></h2>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
